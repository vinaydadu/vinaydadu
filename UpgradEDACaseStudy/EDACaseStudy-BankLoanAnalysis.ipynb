{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out the warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = blue> BANK LOAN ANALYSIS </font>\n",
    "This case study aims to identify patterns which indicate if a client has difficulty paying their installments which may be used for taking actions such as denying the loan, reducing the amount of loan, lending (to risky applicants) at a higher interest rate, etc. This will ensure that the consumers capable of repaying the loan are not rejected. Identification of such applicants using EDA is the aim of this case study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Task 1: Data Reading\n",
    "\n",
    "- ### Subtask 1.1: Read the Application Data.\n",
    "\n",
    "Read the application data file provided and store it in a dataframe `application`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the csv file using 'read_csv'. I have moved the file into my working directory. Using set_option to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "application = pd.read_csv(\"application_data.csv\")\n",
    "application.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of rows and columns in the dataframe\n",
    "application.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check each column datatypes as well as Null counts of the dataframe\n",
    "application.info(verbose = True, null_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the percentage of null/missing values for each column rounded off to 3 digits\n",
    "round((application.isnull().sum()/len(application.index))*100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the statistical summary for the numeric columns (65 float + 41 Integer columns)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "application.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code that provides a list of categorical columns from the dataset (16 columns)\n",
    "list(set(application.columns) - set(application.describe().columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Inferences from Reading Data\n",
    "1. Occupation_type field has 31% Null values. We can find patterns with the field and whether it can be imputed using any other field in the dataset or not<br>\n",
    "2. Most of the fields related to building/property information (i.e. AVG, Mode, MEDI) is having greater than 50% Null values. We can try to analyze if there are related to any specific loan type? We can also take a decision whether to drop these columns or keep them. In a common data analysis scenario, we should not consider such columns to derive specific insights over the entire dataset<br><br>\n",
    "\n",
    "Looking at the statistical summary from describe function, we can infer the below points<br>\n",
    "1. DAYS_EMPLOYED field has some outliers which should be removed/ignored to perform good analysis on that field. In real life, we should ask for clarification on the wrong data and get the data corrected by the client<br>\n",
    "2. AMT_TOTAL_INCOME field has outliers which should be removed/ignored to perform good analysis on that field<br><br>\n",
    "\n",
    "Other Inferences\n",
    "1. Age should be calculated and age groups can be defined to better utilize DAYS_BIRTH field<br>\n",
    "2. Some of the major datapoints are identified by observing the data<br>\n",
    "3. Finding categorical data which will be crucial in slicing the dataset to derive insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Task 2: Data Analysis and Cleaning\n",
    "\n",
    "- ### Subtask 2.1: Draw pie-chart to understand various customer attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customer attributes and composition\n",
    "fig = plt.figure(figsize=(6,4), dpi=1600)\n",
    "#1 rows 2 columns\n",
    "\n",
    "#first row, first column\n",
    "ax1 = plt.subplot2grid((1,2),(0,0))\n",
    "application.TARGET.value_counts(normalize=True).plot.pie(autopct = \"%1.0f%%\",textprops={'fontsize': 6})\n",
    "plt.ylabel('Target', fontsize=5)\n",
    "plt.title('Pays on Time vs Defaulters', fontsize=7)\n",
    "\n",
    "#first row second column\n",
    "ax1 = plt.subplot2grid((1,2), (0,1))\n",
    "application.CODE_GENDER.value_counts(normalize=True).plot.pie(autopct = \"%1.0f%%\",textprops={'fontsize': 6})\n",
    "plt.ylabel('Gender', fontsize=5)\n",
    "plt.title('Gender Composition', fontsize=7)\n",
    "\n",
    "plt.subplots_adjust(wspace=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4), dpi=1600)\n",
    "#1 rows 2 columns\n",
    "\n",
    "#first row, first column\n",
    "ax1 = plt.subplot2grid((1,2),(0,0))\n",
    "application.NAME_EDUCATION_TYPE.value_counts(normalize=True).plot.pie(autopct = \"%1.0f%%\",textprops={'fontsize': 6})\n",
    "plt.ylabel('Education Type', fontsize=6)\n",
    "plt.title('Education Type of Customers', fontsize=7)\n",
    "\n",
    "#first row second column\n",
    "ax1 = plt.subplot2grid((1,2), (0,1))\n",
    "application.NAME_INCOME_TYPE.value_counts(normalize=True).plot.pie(autopct = \"%1.0f%%\",textprops={'fontsize': 6})\n",
    "plt.ylabel('Income Type', fontsize=6)\n",
    "plt.title('Income Type of Customers', fontsize=7)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4), dpi=1600)\n",
    "#1 rows 2 columns\n",
    "\n",
    "#first row, first column\n",
    "ax1 = plt.subplot2grid((1,2), (0,0))\n",
    "application.FLAG_OWN_CAR.value_counts(normalize=True).plot.pie(autopct = \"%1.0f%%\",textprops={'fontsize': 6})\n",
    "plt.ylabel('Own Car', fontsize=5)\n",
    "plt.title('Car Ownership of Customers', fontsize=7)\n",
    "\n",
    "#first row second column\n",
    "ax1 = plt.subplot2grid((1,2), (0,1))\n",
    "application.FLAG_OWN_REALTY.value_counts(normalize=True).plot.pie(autopct = \"%1.0f%%\",textprops={'fontsize': 6})\n",
    "plt.ylabel('Own House', fontsize=5)\n",
    "plt.title('House Ownership of Customers', fontsize=7)\n",
    "\n",
    "plt.subplots_adjust(wspace=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4), dpi=1600)\n",
    "#1 rows 2 columns\n",
    "\n",
    "#first row, first column\n",
    "ax1 = plt.subplot2grid((1,2), (0,0))\n",
    "application.NAME_FAMILY_STATUS.value_counts(normalize=True).plot.pie(autopct = \"%1.0f%%\",textprops={'fontsize': 6})\n",
    "plt.ylabel('Family Status', fontsize=5)\n",
    "plt.title('Family Status of Customers', fontsize=7)\n",
    "\n",
    "#first row second column\n",
    "ax1 = plt.subplot2grid((1,2), (0,1))\n",
    "application.REGION_RATING_CLIENT.value_counts(normalize=True).plot.pie(autopct = \"%1.0f%%\",textprops={'fontsize': 6})\n",
    "plt.ylabel('Region Rating', fontsize=5)\n",
    "plt.title('Region Rating of Customers', fontsize=7)\n",
    "\n",
    "plt.subplots_adjust(wspace=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Subtask 2.2: Find major variables to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##some major variables to be analysed based on observing raw data. Ensure to use head() function, if not used, might face disk failures on slower machines\n",
    "application[['SK_ID_CURR','TARGET','DAYS_BIRTH','DAYS_EMPLOYED','AMT_INCOME_TOTAL','AMT_CREDIT','NAME_CONTRACT_TYPE',\n",
    "             'CODE_GENDER','FLAG_OWN_CAR','FLAG_OWN_REALTY','NAME_TYPE_SUITE','NAME_INCOME_TYPE','NAME_EDUCATION_TYPE',\n",
    "             'NAME_FAMILY_STATUS','NAME_HOUSING_TYPE','OCCUPATION_TYPE','ORGANIZATION_TYPE','REGION_RATING_CLIENT']].head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Subtask 2.3: create AGE field, AGE_GROUP categorical field and derive insights based on age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating age based on number of days_birth and converting into year. Each year is calculated as 365 days ignoring effect of leap year \n",
    "application['AGE'] = application['DAYS_BIRTH'].div(365).round(1).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting AGE into categorical data to draw better insights based on age group\n",
    "application[\"AGE_GROUP\"] = pd.cut(application.AGE,[0,30,45,60,9999],labels=[\"<30\",\"30-45\",\"45-60\",\"60+\"])\n",
    "application.AGE_GROUP.value_counts(normalize=True).plot.pie(autopct = \"%1.0f%%\")\n",
    "plt.title('Customer Composition based on Age Group', fontsize = 12)\n",
    "plt.ylabel(\"Age Group\", fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#understanding the default amounts per age group.\n",
    "#First groupby the required fields and sumup the total amount of loan per target and age_group\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "gr_Age_Group = application[['TARGET','AGE_GROUP','AMT_CREDIT']].groupby(['TARGET','AGE_GROUP'],as_index=False).sum('AMT_CREDIT')\n",
    "gr_Age_Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot the above data so that we can understand the default amount per age group\n",
    "pivot_Age_Group = gr_Age_Group.pivot(index='AGE_GROUP', columns='TARGET', values='AMT_CREDIT')\n",
    "pivot_Age_Group.plot(kind='bar', stacked=True)\n",
    "plt.title(\"Default Rates per Age Group\")\n",
    "plt.xlabel(\"Age Group\")\n",
    "plt.ylabel(\"Default Amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Subtask 2.4: create Income_Level field and derive insights based on income level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Total Income into categorical data to draw better insights based on income levels\n",
    "application[\"INCOME_LEVEL\"] = pd.cut(application.AMT_INCOME_TOTAL,[0,100000,200000,300000,9999999999],labels=[\"LOW\",\"MIDDLE\",\"RICH\",\"ULTRARICH\"])\n",
    "application.INCOME_LEVEL.value_counts(normalize=True).plot.pie(autopct = \"%1.0f%%\")\n",
    "plt.title('Customer Composition based on Income Level', fontsize = 12)\n",
    "plt.ylabel(\"Income Level\", fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#understanding the default amounts based on income level.\n",
    "#First groupby the required fields and sumup the total amount of loan per target and income level\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "gr_income_level = application[['TARGET','INCOME_LEVEL','AMT_CREDIT']].groupby(['TARGET','INCOME_LEVEL'],as_index=False).sum('AMT_CREDIT')\n",
    "gr_income_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot the above data so that we can understand the default amount per income level\n",
    "pivot_Income_Level = gr_income_level.pivot(index='INCOME_LEVEL', columns='TARGET', values='AMT_CREDIT')\n",
    "pivot_Income_Level.plot(kind='bar', stacked=True)\n",
    "plt.title(\"Default Rates per Income Level\")\n",
    "plt.xlabel(\"Income Level\")\n",
    "plt.ylabel(\"Default Amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Subtask 2.5: Analyze DAYS_EMPLOYED field and find outliers. Reduce the dataset to get only legitimate values and then find outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Analysing and handling outliers in DAYS_EMPLOYED field. This field is supposed to have values less than 0 \n",
    "#indicating How many days before the application the person started current employment\n",
    "application.boxplot(column=['DAYS_EMPLOYED'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since this field is supposed to have values <0, we will ignore any values above 0\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "application[application.DAYS_EMPLOYED<=0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new dataframe after removing outlier cases for AMT_CREDIT from original dataframe\n",
    "application_days_employed_correct_data = application[application.DAYS_EMPLOYED<=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling outliers in total income field and plotting\n",
    "application_days_employed_correct_data.boxplot(\"DAYS_EMPLOYED\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Subtask 2.6: Analyze AMT_CREDIT field and handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#handling outliers in loan amount field\n",
    "application.boxplot(column=['AMT_CREDIT'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#finding the correct cutoff based on quantiles\n",
    "application.AMT_CREDIT.quantile([0.5,0.7,0.9,0.95,0.99,0.995,0.998])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describe to find statistical summary again and observe the change in AMT_CREDIT field. Taking the summary at 95 percentile\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "application[application.AMT_CREDIT<1350000].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will lose 16355 rows where AMT_CREDIT is above the 99.8 percentile. This will help in removing the outlier cases\n",
    "307511- 291156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new dataframe after removing outlier cases for AMT_CREDIT from original dataframe.Taking the outliers at 95 percentile value\n",
    "application_loan_outliers = application[application.AMT_CREDIT<=1350000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling outliers in AMT_CREDIT field and plotting. \n",
    "application_loan_outliers.boxplot(\"AMT_CREDIT\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Subtask 2.7: Analyze AMT_INCOME_TOTAL field and handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling outliers in loan amount field\n",
    "application.boxplot(column=['AMT_INCOME_TOTAL'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the correct cutoff based on quantiles\n",
    "application.AMT_INCOME_TOTAL.quantile([0.5,0.7,0.9,0.95,0.99,0.995,0.998])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Describe to find statistical summary again and observe the change in AMT_CREDIT field. Taking summary at 99.8 percentile\n",
    "application[application.AMT_INCOME_TOTAL<337500].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will lose 15825 rows where AMT_INCOME_TOTAL is above the 95 percentile. This will help in removing the outlier cases\n",
    "307511 -291686"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new dataframe after removing outlier cases for AMT_INCOME_TOTAL from original dataframe.Taking the outliers at 95 percentile value\n",
    "application_Total_Income_outliers = application[application.AMT_INCOME_TOTAL<=337500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling outliers in total income field and plotting. \n",
    "application_Total_Income_outliers.boxplot(\"AMT_INCOME_TOTAL\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Subtask 2.8: Understanding Target Variable with respect to other variables<br>\n",
    "\n",
    "Understanding the data with respect different variable and target variable. This is a very crucial part of data analysis \n",
    "and by understanding the various variables available and their potential impact on the target variable, we would be able to\n",
    "produce a better analysis\n",
    "\n",
    "- ###### Subtask 2.8.1: GENDER cleanup for XNA values and percentage of defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the distinct gender values and removing XNA values\n",
    "application.drop(application[application.CODE_GENDER =='XNA'].index, inplace=True)\n",
    "gr_gender = application[['SK_ID_CURR','TARGET','CODE_GENDER']].groupby(['TARGET','CODE_GENDER']).count()\n",
    "\n",
    "#pivot the above data so that we can understand the default amount per gender\n",
    "gr_gender.reset_index().pivot('CODE_GENDER', 'TARGET', 'SK_ID_CURR').plot.bar(stacked=True)\n",
    "plt.title(\"Gender Default Rates\")\n",
    "plt.xlabel(\"Gender\")\n",
    "plt.ylabel(\"Default %age\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###### Subtask 2.8.2: Contract types and the percentage of defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_name_cont_type = application[['SK_ID_CURR','TARGET','NAME_CONTRACT_TYPE']].groupby(['TARGET','NAME_CONTRACT_TYPE']).count()\n",
    "\n",
    "#pivot the above data so that we can understand the default amount per income level\n",
    "gr_name_cont_type.reset_index().pivot('NAME_CONTRACT_TYPE', 'TARGET', 'SK_ID_CURR').plot.bar(stacked=True)\n",
    "plt.title(\"Contract Type Default Rates\")\n",
    "plt.xlabel(\"Contract Type\")\n",
    "plt.ylabel(\"Default %age\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###### Subtask 2.8.3: Loans granted and education type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding mean total income based on educationtype. Comparing the loan granted with respect to avg income per incometype.\n",
    "#Using subplots to compare side-by-side\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Avg Income per Education Type\", fontsize=12)\n",
    "plt.ylabel(\"Avg Income\")\n",
    "mean_edu = application.groupby('NAME_EDUCATION_TYPE')['AMT_INCOME_TOTAL'].mean()\n",
    "mean_edu.plot.bar()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Avg Loan Amount per Education Type\", fontsize=12)\n",
    "plt.ylabel(\"Avg Loan Amount\")\n",
    "mean_loan_edu = application.groupby('NAME_EDUCATION_TYPE')['AMT_CREDIT'].mean()\n",
    "mean_loan_edu.plot.bar()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###### Subtask 2.8.4: Loans granted and occupation type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding mean total income based on occupationtype. Comparing the loan granted with respect to avg income per occupation\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Avg Income per occupation\", fontsize=12)\n",
    "plt.ylabel(\"Avg Income\")\n",
    "mean_occu = application.groupby('OCCUPATION_TYPE')['AMT_INCOME_TOTAL'].mean()\n",
    "mean_occu.plot.bar()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Avg Loan Amount per occupation\", fontsize=12)\n",
    "plt.ylabel(\"Avg Loan Amount\")\n",
    "mean_loan_occu = application.groupby('OCCUPATION_TYPE')['AMT_CREDIT'].mean()\n",
    "mean_loan_occu.plot.bar()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###### Subtask 2.8.5: Loans granted and income type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding mean total income based on incometype. Comparing the loan granted with respect to avg income per incometype\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Avg Income per Income Type\", fontsize=12)\n",
    "plt.ylabel(\"Avg Income\")\n",
    "mean_incometype = application.groupby('NAME_INCOME_TYPE')['AMT_INCOME_TOTAL'].mean()\n",
    "mean_incometype.plot.bar()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Avg Loan Amount per Income Type\", fontsize=12)\n",
    "plt.ylabel(\"Avg Loan Amount\")\n",
    "mean_loan_income = application.groupby('NAME_INCOME_TYPE')['AMT_CREDIT'].mean()\n",
    "mean_loan_income.plot.bar()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###### Subtask 2.8.6: other insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the below are a few more dataframes that can be further used to analyse the default rates per variable type. For the purpose of this case study, we are not going to analyse these in more details\n",
    "\n",
    "gr_owncar = application[['SK_ID_CURR','TARGET','FLAG_OWN_CAR']].groupby(['TARGET','FLAG_OWN_CAR']).count()\n",
    "gr_ownrealty = application[['SK_ID_CURR','TARGET','FLAG_OWN_REALTY']].groupby(['TARGET','FLAG_OWN_REALTY']).count()\n",
    "gr_name_type_suite = application[['SK_ID_CURR','TARGET','NAME_TYPE_SUITE']].groupby(['TARGET','NAME_TYPE_SUITE']).count()\n",
    "gr_family_status = application[['SK_ID_CURR','TARGET','NAME_FAMILY_STATUS']].groupby(['TARGET','NAME_FAMILY_STATUS']).count()\n",
    "gr_name_housing_type = application[['SK_ID_CURR','TARGET','NAME_HOUSING_TYPE']].groupby(['TARGET','NAME_HOUSING_TYPE']).count()\n",
    "gr_org_type = application[['SK_ID_CURR','TARGET','ORGANIZATION_TYPE']].groupby(['TARGET','ORGANIZATION_TYPE']).count()\n",
    "\n",
    "gr_edu_type = application[['SK_ID_CURR','TARGET','NAME_EDUCATION_TYPE']].groupby(['TARGET','NAME_EDUCATION_TYPE']).count()\n",
    "gr_occ_type = application[['SK_ID_CURR','TARGET','OCCUPATION_TYPE']].groupby(['TARGET','OCCUPATION_TYPE']).count()\n",
    "gr_income_type = application[['SK_ID_CURR','TARGET','NAME_INCOME_TYPE']].groupby(['TARGET','NAME_INCOME_TYPE']).count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferences from Data analysis\n",
    "\n",
    "1) The %age of defaulters are high at around 8% and the major aim of this analysis is to understand the patterns around this and suggest remedies so that %age of defaulters are reduced <br><br>\n",
    "2) Loans granted to female population are higher than loans granted to male population. Also - The default rate of female population is lesser at 7% compared to male population at 10%<br><br>\n",
    "3) 85% of the customers are above 30+ years. Default rates are higher for <30 years age group. As people become older, the default rates are getting smaller. The default rates (as a %of loan amount within the age group) for <30 age group is close to 11% where as it is reduced to 5.2% for 60+ agegroup<br><br>\n",
    "4) Middle Income Group have secured the highest loan amount from the bank. These people have also the highest %age default amount causing losses to the bank<br><br>\n",
    "5) Cash Loans have higher default at 8.3% compared to Revolving loans at 5.4%<br><br>\n",
    "6) Highly educated applicants stand a better chance to get higher amount of loan credit<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Subtask 2.9: Splitting the datasets between defaulters and customers who pay on time<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#picking some relevant columns to find correlation among the customers who pay on time\n",
    "application_0 = application[['AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY',\n",
    "                             'AMT_GOODS_PRICE','REGION_POPULATION_RELATIVE','CNT_FAM_MEMBERS','REGION_RATING_CLIENT',\n",
    "                             'EXT_SOURCE_2','DAYS_LAST_PHONE_CHANGE','OBS_30_CNT_SOCIAL_CIRCLE','DEF_30_CNT_SOCIAL_CIRCLE',\n",
    "                             'OBS_60_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE','AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "                             'AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_WEEK','AMT_REQ_CREDIT_BUREAU_MON',\n",
    "                             'AMT_REQ_CREDIT_BUREAU_QRT','AMT_REQ_CREDIT_BUREAU_YEAR']].loc[application['TARGET'] == 0]\n",
    "\n",
    "#picking some relevant columns to find correlation among the defaulters\n",
    "application_1 = application[['AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY',\n",
    "                             'AMT_GOODS_PRICE','REGION_POPULATION_RELATIVE','CNT_FAM_MEMBERS','REGION_RATING_CLIENT',\n",
    "                             'EXT_SOURCE_2','DAYS_LAST_PHONE_CHANGE','OBS_30_CNT_SOCIAL_CIRCLE','DEF_30_CNT_SOCIAL_CIRCLE',\n",
    "                             'OBS_60_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE','AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "                             'AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_WEEK','AMT_REQ_CREDIT_BUREAU_MON',\n",
    "                             'AMT_REQ_CREDIT_BUREAU_QRT','AMT_REQ_CREDIT_BUREAU_YEAR']].loc[application['TARGET'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding correlation between different datafields for customers who pay on time\n",
    "corr0 = application_0.corr()\n",
    "msk = np.zeros_like(corr0)\n",
    "msk[np.triu_indices_from(msk)] = True\n",
    "f, ax = plt.subplots(figsize = (8,5))\n",
    "with sns.axes_style(\"white\"):\n",
    "    ax = sns.heatmap(corr0, mask=msk, vmax=.3, square=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding correlation between different datafields for customers who pay on time\n",
    "corr1 = application_1.corr()\n",
    "msk = np.zeros_like(corr1)\n",
    "msk[np.triu_indices_from(msk)] = True\n",
    "f, ax = plt.subplots(figsize = (8,5))\n",
    "with sns.axes_style(\"white\"):\n",
    "    ax = sns.heatmap(corr1, mask=msk, vmax=.3, square=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Subtask 2.10: Merge application and previous application datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file using 'read_csv'. I have moved the file into my working directory. Using set_option to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "prevapplication = pd.read_csv(\"previous_application.csv\")\n",
    "prevapplication.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = application.merge(prevapplication, left_on = 'SK_ID_CURR', right_on = 'SK_ID_CURR', how='inner')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Removing XNA industry to identify clusters of other industries where most applications are made\n",
    "merged_df_industry = merged_df[['SK_ID_CURR','NAME_SELLER_INDUSTRY','SK_ID_PREV']].loc[merged_df['NAME_SELLER_INDUSTRY'] !=\"XNA\"]\n",
    "merged_df_industry.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping the industry dataframe\n",
    "industry_applicants = merged_df_industry[['SK_ID_PREV','NAME_SELLER_INDUSTRY']].groupby(['NAME_SELLER_INDUSTRY'],as_index=False).count()\n",
    "\n",
    "#plotting a pie to understand where most applications are made\n",
    "industry_applicants.SK_ID_PREV.plot.pie(autopct = \"%1.0f%%\")\n",
    "plt.title('Industry wise Loan Application', fontsize = 12)\n",
    "plt.ylabel(\"Industry\", fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "industry_applicants.sort_values(\"SK_ID_PREV\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspecting the merged dataset based on the client type and contract statuses. Each of the client types are independent but provides a good relative view of the size of bars\n",
    "gr_contract_status = merged_df[['SK_ID_PREV','NAME_CONTRACT_STATUS','NAME_CLIENT_TYPE']].groupby(['NAME_CONTRACT_STATUS','NAME_CLIENT_TYPE']).count()\n",
    "\n",
    "#pivot the above data so that we can understand the default amount per gender\n",
    "gr_contract_status.reset_index().pivot('NAME_CLIENT_TYPE', 'NAME_CONTRACT_STATUS', 'SK_ID_PREV').plot.bar(stacked=True)\n",
    "plt.title(\"Client Wise Loan Status\")\n",
    "plt.xlabel(\"Contract Status\")\n",
    "plt.ylabel(\"%age\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the 'object' variables of Previous application data(prevapplication). Doing this in a different way than the above stacked charted for practice\n",
    "# for 'refused', 'approved' & 'canceled' Contract status\n",
    "\n",
    "refused = prevapplication[prevapplication.NAME_CONTRACT_STATUS=='Refused']\n",
    "approved = prevapplication[prevapplication.NAME_CONTRACT_STATUS=='Approved']\n",
    "canceled = prevapplication[prevapplication.NAME_CONTRACT_STATUS=='Canceled']\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(15,5)) \n",
    "chart1 = sns.countplot(ax=ax1,x=refused['PRODUCT_COMBINATION'], data=refused, \n",
    "              order= refused['PRODUCT_COMBINATION'].value_counts().index, orient=\"h\")\n",
    "ax1.set_title(\"Refused\", fontsize=10)\n",
    "ax1.set_xlabel('%s' %'PRODUCT_COMBINATION')\n",
    "ax1.set_ylabel(\"Count of Loans\")\n",
    "chart1.set_xticklabels(chart1.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "\n",
    "chart2= sns.countplot(ax=ax2,x=approved['PRODUCT_COMBINATION'], data=approved, \n",
    "              order= approved['PRODUCT_COMBINATION'].value_counts().index,orient=\"h\")\n",
    "ax2.set_title(\"Approved\", fontsize=10)\n",
    "ax2.set_xlabel('%s' %'PRODUCT_COMBINATION')\n",
    "ax2.set_ylabel(\"Count of Loans\")\n",
    "chart2.set_xticklabels(chart2.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "\n",
    "chart3 = sns.countplot(ax=ax3,x=canceled['PRODUCT_COMBINATION'], data=canceled, \n",
    "              order= canceled['PRODUCT_COMBINATION'].value_counts().index,orient=\"h\")\n",
    "ax3.set_title(\"Canceled\", fontsize=10)\n",
    "ax3.set_xlabel('%s' %'PRODUCT_COMBINATION')\n",
    "ax3.set_ylabel(\"Count of Loans\")\n",
    "chart3.set_xticklabels(chart3.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferences from Data analysis\n",
    "\n",
    "1) The merged dataframe has significantly higher row count compared to application dataset indicating that there are multiple previous applications for one current application <br><br>\n",
    "2) It is very clear from the pie chart that consumer electronics and Connectivity industries are the ones where most of the loans applications are made. Hence, these industries will give most loan business to the bank<br><br>\n",
    "3) Repeater clients have a good number of canceled and Unused offer loans, so the banks loan marketing departments can follow-up with these customers<br><br>\n",
    "4) Most of refused loans were for Product combination of 'Cash X-Sell:low'. It is also clear that most of loans were approved for 'POS household with interest'. And most Canceled loans were for 'Cash loans'<br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
